# LSTM Language Model mit TensorFlow.js

## ğŸ“Œ Projektbeschreibung
Dieses Projekt ist ein einfaches autoregressives Sprachmodell, das mit einem LSTM-Netzwerk in TensorFlow.js trainiert wurde. Es erlaubt dem Nutzer, interaktiv ein deutsches TextstÃ¼ck zu generieren, indem jeweils das nÃ¤chste wahrscheinliche Wort vorhergesagt wird.

## ğŸ”§ Projektstruktur


## ğŸ’¡ Funktionen

- Wortvorhersage mit LSTM
- Interaktive Buttons:
  - ğŸ” Vorhersage
  - â¡ Weiter (wahrscheinlichstes Wort)
  - ğŸ” Auto (max. 10 WÃ¶rter)
  - â¹ Stop
  - ğŸ”„ Reset
- Visualisierung der Top-k-Wahrscheinlichkeiten

## ğŸ§  Modellarchitektur

- 2 LSTM-Layer, je 100 Units
- Dense Softmax-Ausgabe
- Optimizer: Adam (LR = 0.01)
- Loss: Categorical Crossentropy
- Batch Size: 32

## ğŸ§ª Experimente & Evaluation

- Accuracy bei Top-k: k=1,5,10,20,100
- Perplexity-Berechnung
- Training auf Subset deutscher Texte (z.B. Gutenberg, Bundestag)

## ğŸ’» Voraussetzungen

- Lokaler Webserver (z.â€¯B. VS Code + Live Server)
- Chrome oder Firefox
- Internetzugang (fÃ¼r CDN von TensorFlow.js)

## ğŸ”— Quellen

- TensorFlow.js Demos: https://www.tensorflow.org/js/demos
- LSTM-Textgenerierung: https://github.com/seyedsaeidmasoumzadeh/Predict-next-word
